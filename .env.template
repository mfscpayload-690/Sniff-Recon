# =============================================================================
# AI PROVIDER API KEYS
# =============================================================================
# Add your API keys below. At least ONE provider is required.
# Get free API keys from:
#   - Groq: https://console.groq.com (Recommended - Fast & Free)
#   - OpenAI: https://platform.openai.com/api-keys
#   - Anthropic: https://console.anthropic.com
#   - Google Gemini: https://makersuite.google.com/app/apikey
#   - xAI: https://console.x.ai

GROQ_API_KEY=your_groq_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here
XAI_API_KEY=your_xai_api_key_here

# =============================================================================
# LOCAL LLM (OFFLINE MODE)
# =============================================================================
# Want to analyze packets OFFLINE? Enable Ollama for 100% local AI analysis.
# Setup: https://ollama.ai
#   1. Install: curl -fsSL https://ollama.ai/install.sh | sh
#   2. Start: ollama serve
#   3. Pull model: ollama pull qwen2.5-coder:7b
#   4. Set OLLAMA_ENABLED=true below

OLLAMA_ENABLED=false
OLLAMA_MODEL=qwen2.5-coder:7b

# =============================================================================
# ADVANCED SETTINGS (Optional - Most users can ignore this section)
# =============================================================================

# --- AI Model Selection ---
# Override default models (leave blank to use defaults)
GROQ_MODEL=llama-3.3-70b-versatile
OPENAI_MODEL=gpt-3.5-turbo
ANTHROPIC_MODEL=claude-3-sonnet-20240229
GOOGLE_MODEL=gemini-2.0-flash
XAI_MODEL=grok-beta

# --- Load Balancing Strategy ---
# How to distribute queries across multiple providers
# Options: weighted, round_robin
LOAD_BALANCING_STRATEGY=weighted

# Provider weights (higher = more queries)
GROQ_WEIGHT=30
OPENAI_WEIGHT=25
GEMINI_WEIGHT=25
XAI_WEIGHT=25
ANTHROPIC_WEIGHT=20
OLLAMA_WEIGHT=30

# --- File Processing ---
# Maximum file size for uploads (MB)
MAX_FILE_SIZE_MB=200

# Chunk large files for processing
CHUNK_SIZE_MB=5
MAX_PACKETS_PER_CHUNK=5000

# --- Security ---
# Rate limiting (queries per minute)
AI_RATE_LIMIT_PER_MINUTE=30

# Allowed file extensions (comma-separated)
ALLOWED_EXTENSIONS=pcap,pcapng,csv,txt

# --- Output ---
# Where to save exported reports
OUTPUT_DIR=./output

# --- UI Customization ---
# Optional: Add your own donation link (leave blank for default)
BUYMEACOFFEE_URL=